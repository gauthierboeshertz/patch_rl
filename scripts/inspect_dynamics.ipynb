{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "import hydra\n",
    "import sys\n",
    "import einops\n",
    "sys.path.append('../')\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from src.datasets import SequenceImageTransitionDataset\n",
    "from src.patch_vae import PatchVAE\n",
    "from src.vqvae import VQVAE\n",
    "from src.patch_utils import  plot_image_patches, patches_to_image, image_to_patches\n",
    "from src.mask_utils import make_gt_causal_mask, aggreg_heads\n",
    "from src.dynamics_model import AttentionDynamicsModel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_data = \"2022.11.25\"\n",
    "folder_time = \"101240\"\n",
    "model_info = \"best_val\"\n",
    "model_name = \"patch_vae\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = f\"../outputs/dynamics/{model_name}/{folder_data}/{folder_time}/.hydra/config.yaml\"\n",
    "config = OmegaConf.load(config_path)\n",
    "config[\"env\"][\"num_transitions\"] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/visual_{}transitions_{}_{}_{}_{}{}no_targets.npz\".format(config[\"env\"][\"num_transitions\"],config[\"env\"][\"num_sprites\"],(\"all_sprite_mover\"if config[\"env\"][\"all_sprite_mover\"] else  \"discrete_all_sprite_mover\" if config[\"env\"][\"discrete_all_sprite_mover\"] else \"select_move\"),config[\"env\"][\"random_init_places\"],config[\"env\"][\"num_action_repeat\"],\"instantmove\" if config[\"env\"].get(\"instant_move\",False) else \"\")\n",
    "#data_path = \"/cluster/home/gboeshertz/patch_rl/data/visual_180transitions_4_all_sprite_mover_False_4instantmove.npz\"\n",
    "print(data_path)\n",
    "dataset = SequenceImageTransitionDataset(data_path=data_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image,action, next_image,_ =  dataset[100]#80\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.mask_utils\n",
    "from src.mask_utils import gt_reward_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_POS_IMG = [[9,16,22,29],\n",
    "                  [35,42,22,29],\n",
    "                  [86,93,48,55],\n",
    "                  [86,93,73,80]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[0,0,9:16,22:29] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[1,2,86:93,48:55] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_reward_function(image,next_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_dec_path = config[\"encoder_decoder_path\"]\n",
    "import os \n",
    "encoder_decoder_conf = OmegaConf.load(os.path.join(os.path.dirname(config[\"encoder_decoder_path\"]), \".hydra/config.yaml\"))[\"encoder_decoder\"]\n",
    "\n",
    "config[\"encoder_decoder\"] = encoder_decoder_conf\n",
    "\n",
    "enc_dec = hydra.utils.instantiate(config[\"encoder_decoder\"]) #PatchVAE(**config[\"model\"][\"patch_vae\"])\n",
    "\n",
    "er = enc_dec.load_state_dict(torch.load(enc_dec_path,map_location=torch.device('cpu')))\n",
    "enc_dec.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_image = image/255.\n",
    "recons_image = enc_dec.reconstruct_image(p_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moog_demos.example_configs.bouncing_sprites import get_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_config(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image[0].permute(1,2,0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((recons_image[0].permute(1,2,0)*255).byte())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamics_model_path = f\"../outputs/dynamics/{model_name}/{folder_data}/{folder_time}/{model_info}_dynamics.pt\"\n",
    "config[\"dynamics\"][\"num_patches\"] = enc_dec.num_patches\n",
    "config[\"dynamics\"][\"action_dim\"] = action.shape[-1]\n",
    "config[\"dynamics\"][\"in_features\"] = enc_dec.embed_dim\n",
    "config[\"dynamics\"][\"num_actions\"] = config[\"env\"][\"num_sprites\"]\n",
    "\n",
    "\n",
    "dynamics_model = hydra.utils.instantiate(config[\"dynamics\"])\n",
    "dynamics_model.load_state_dict(torch.load(dynamics_model_path,map_location=torch.device('cpu')))\n",
    "dynamics_model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_mask(mask,num_actions=4,patch_slice = (0,-1)):\n",
    "  # The model didn't generate `<START>` in the output. Skip it.\n",
    "  labels = [\"patch{}\".format(i) for i in range(config[\"dynamics\"][\"num_patches\"])]\n",
    "  labels = labels + [\"action{}\".format(i) for i in range(num_actions)]\n",
    "  ax = plt.gca()\n",
    "  \n",
    "  mat_to_plot = mask[patch_slice[0]:patch_slice[1],patch_slice[0]:patch_slice[1]]\n",
    "  mat_to_plot = np.hstack((mat_to_plot,mask[patch_slice[0]:patch_slice[1],-num_actions:]))\n",
    "  ax.matshow(mat_to_plot, cmap='viridis')\n",
    "  \n",
    "  labels_to_plot = labels[patch_slice[0]:patch_slice[1]]\n",
    "  labels_to_plot_act = labels_to_plot + [\"action{}\".format(i) for i in range(num_actions)]\n",
    "  \n",
    "  ax.set_xticks(range(len(labels_to_plot_act)))\n",
    "  ax.set_yticks(range(len(labels_to_plot)))\n",
    "  ax.set_xticklabels(\n",
    "      labels_to_plot_act, rotation=90)\n",
    "\n",
    "  ax.set_yticklabels(labels_to_plot)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_patches(obs,action,patch_vae,dynamics_model,patches_embeddings=None):\n",
    "    \n",
    "    if patches_embeddings is None:\n",
    "        patches_embeddings = patch_vae.get_encoding_for_dynamics(obs/255.)\n",
    "    patches_embeddings = einops.rearrange(patches_embeddings, \"(b n) c -> b n c\", b=obs.shape[0])\n",
    "    \n",
    "    dynamic_patches, _ = dynamics_model([patches_embeddings,action])\n",
    "    dynamic_patches = einops.rearrange(dynamic_patches, \"(b t) n c -> b t  n c\",b=obs.shape[0])\n",
    "    \n",
    "    return dynamic_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dynamic_embeddings = get_next_patches(image,action, enc_dec,dynamics_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_embeddings = dynamic_embeddings[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dynamic_embeddings = einops.rearrange(dynamic_embeddings, \"b n c -> (b n) c\", )\n",
    "dyn_recons = enc_dec.decode(dynamic_embeddings)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_recons.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_recons = einops.rearrange(dyn_recons, \"(b n) c h w -> b n c h w\", n=enc_dec.num_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dyn_recons_image = patches_to_image(dyn_recons, patch_size=16, image_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((image[1].permute(1,2,0)).byte())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((dyn_recons_image[0].permute(1,2,0)*255).byte())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_patches(image[0], patch_size=(enc_dec.patch_size,enc_dec.patch_size), num_patches_sqrt=image[0].shape[2]//enc_dec.patch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_patches(image[1], patch_size=(enc_dec.patch_size,enc_dec.patch_size), num_patches_sqrt=image[0].shape[2]//enc_dec.patch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_patches(dyn_recons_image[0]*255, patch_size=(enc_dec.patch_size,enc_dec.patch_size), num_patches_sqrt=image[0].shape[2]//enc_dec.patch_size);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_mask = make_gt_causal_mask(image[:2].unsqueeze(0),action[0],patch_size=16,num_sprites=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_slice = (30,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(gt_mask[0].detach(),patch_slice=patch_slice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "causal_mask, attention_weights = dynamics_model.get_causal_mask((image/255.), action,encoder=enc_dec,head_fusion=\"max\",discard_ratio=0.9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_layer = aggreg_heads(attention_weights[0,0],head_fusion=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mask_utils import attn_rollout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask( causal_mask[0].detach() > 0.2, patch_slice=patch_slice)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights = dynamics_model.get_attn_weights(image/255., action,encoder=enc_dec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_mask(attention_weights[0,0,3].detach(),patch_slice=patch_slice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult = attention_weights.prod(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rep_attn = attention_weights.repeat(1,1,1,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from functools import reduce\n",
    "from itertools import combinations, chain\n",
    "from scipy.sparse.csgraph import connected_components\n",
    "import random\n",
    "\n",
    "\n",
    "def get_default_mask(s, a):\n",
    "    \"\"\" assumes set-based s and a... so shape should be (n_componenents, *component_shape) \"\"\"\n",
    "    if len(a.shape) == 1:\n",
    "        a.reshape(1, -1)\n",
    "\n",
    "    mask_dim = len(s) + len(a)\n",
    "    mask_shape = (mask_dim, mask_dim)\n",
    "    return np.ones(mask_shape)\n",
    "\n",
    "\n",
    "def batch_get_default_mask(s, a):\n",
    "    \"\"\" Batch version of get default mask \"\"\"\n",
    "    s_shape = s.shape\n",
    "    a_shape = a.shape\n",
    "    if len(a_shape) == 2:\n",
    "        assert len(a_shape) > 1\n",
    "        a.reshape(-1, 1, a_shape[-1])\n",
    "\n",
    "    mask_dim = s_shape[1] + a_shape[1]\n",
    "    mask_shape = (s_shape[0], mask_dim, mask_dim)\n",
    "    return np.ones(mask_shape)\n",
    "\n",
    "\n",
    "def get_cc_from_mask(mask):\n",
    "    \"\"\"\n",
    "    Converts a mask into a list of CC indices tuples.\n",
    "    E.g., if mask is [[1,0,0,0],[0,1,0,0],[0,0,1,1],[0,0,1,1]],\n",
    "    this will return [array([0]), array([1]), array([2, 3])]\n",
    "\n",
    "    Note that the mask should be a square, so in case we have (s, a) x (s2,),\n",
    "    we should first dummy a2 columns to form a square mask. \n",
    "    \"\"\"\n",
    "    ccs = connected_components(mask)\n",
    "    num_ccs, cc_idxs = ccs\n",
    "    return [np.where(cc_idxs == i)[0] for i in range(num_ccs)]\n",
    "\n",
    "\n",
    "def powerset(n):\n",
    "    xs = list(range(n))\n",
    "    return list(chain.from_iterable(combinations(xs, n) for n in range(n + 1)))\n",
    "\n",
    "\n",
    "def reduce_cc_list_by_union(cc_list, max_ccs):\n",
    "    \"\"\"Takes a cc list that is too long and merges some components to bring it\n",
    "    to max_ccs\"\"\"\n",
    "    while len(cc_list) > max_ccs:\n",
    "        i, j = np.random.choice(range(1, len(cc_list) - 1), 2, replace=False)\n",
    "        if (j == 0) or (j == len(cc_list) - 1):\n",
    "            continue  # don't want to delete the base\n",
    "        cc_list[i] = np.union1d(cc_list[i], cc_list[j])\n",
    "        del cc_list[j]\n",
    "    return cc_list\n",
    "\n",
    "\n",
    "def reduce_cc_list_smallest_first(cc_list, max_ccs):\n",
    "    \"\"\"Takes a cc list that is too long and merges some components to bring it\n",
    "    to max_ccs\"\"\"\n",
    "    while len(cc_list) > max_ccs:\n",
    "        ccs_len = [len(cc) for cc in cc_list]\n",
    "        smallest_len = min(ccs_len)\n",
    "        ccs_min_len_idx = [i for i, cc in enumerate(cc_list) if len(cc) == smallest_len]\n",
    "        if len(ccs_min_len_idx) == 1:\n",
    "            i = ccs_min_len_idx[0]\n",
    "            j = np.random.choice([k for k in range(len(cc_list)) if k != i])\n",
    "        else:\n",
    "            i, j = np.random.choice(ccs_min_len_idx, 2, replace=False)\n",
    "        cc_list[i] = np.union1d(cc_list[i], cc_list[j])\n",
    "        del cc_list[j]\n",
    "    return cc_list\n",
    "\n",
    "def disentangled_components(cc_lst):\n",
    "    \"\"\"Converts connected component list into a list of disentangled subsets\n",
    "    of the indices.\n",
    "    \"\"\"\n",
    "    subsets = powerset(len(cc_lst))\n",
    "    res = []\n",
    "    for subset in subsets:\n",
    "        res.append(reduce(np.union1d, [cc_lst[i] for i in subset], np.array([])).astype(np.int64))\n",
    "    return set(map(tuple, res))\n",
    "\n",
    "\n",
    "def get_dcs_from_mask(mask, max_ccs = 6):\n",
    "    cc = get_cc_from_mask(mask)\n",
    "    return disentangled_components(reduce_cc_list_smallest_first(cc, max_ccs))\n",
    "\n",
    "\n",
    "def transitions_and_masks_to_proposals(t1,\n",
    "                                       t2,\n",
    "                                       m1,\n",
    "                                       m2,\n",
    "                                       max_samples=10,\n",
    "                                       max_ccs=20):\n",
    "    \"\"\" \n",
    "    assumes set-based s and a... so shape should be (n_components, *component_shape)\n",
    "    Takes two transitions with their masks, and combines them\n",
    "    using connected-component relabeling to form proposals\n",
    "    Returns a list of tuples of ((s1, a1, s2) proposal, disconnected_component_idxs).\n",
    "    \"\"\"\n",
    "    \n",
    "    sa1, s21 = t1\n",
    "    sa2, s22 = t2\n",
    "\n",
    "    # get_dcs_from_mask should return a set of tuples of indices, inc. the empty tuple\n",
    "    # where the subgraph represented by each tuple is disconnected from the result of \n",
    "    # the graph. Note that mask should be square, so columns corresp. to action idxs are \n",
    "    # dummy columns.\n",
    "    #\n",
    "    # E.g., if mask is [[1,0,0,0],[0,1,0,0],[0,0,1,1],[0,0,1,1]],\n",
    "    # this function should return:\n",
    "    #   set([ (,), (0,), (1,), (0,1), (2, 3), (0, 2, 3), (1, 2, 3), (0, 1, 2, 3)  ])\n",
    "\n",
    "    print(\"creating disconnected components\")\n",
    "    dc1 = get_dcs_from_mask(m1, max_ccs)\n",
    "    dc2 = get_dcs_from_mask(m2, max_ccs)\n",
    "\n",
    "    print(\"created disconnected components\")\n",
    "    # get shared connected components in random order\n",
    "    shared_dc = list(dc1.intersection(dc2))\n",
    "    random.shuffle(shared_dc)\n",
    "\n",
    "    # subsample shared_dc down to max_samples\n",
    "    if len(shared_dc) > max_samples:\n",
    "        shared_dc = shared_dc[:max_samples]\n",
    "\n",
    "    all_idxs = set(range(len(sa1)))\n",
    "\n",
    "    res = []\n",
    "    for dc in shared_dc:\n",
    "        not_dc = list(all_idxs - set(dc))\n",
    "    dc = list(dc) # (0, 2)\n",
    "\n",
    "    proposed_sa = np.zeros_like(sa1)\n",
    "    proposed_s2 = np.zeros_like(sa1)\n",
    "\n",
    "    proposed_sa[dc]     = sa1[dc]\n",
    "    proposed_sa[not_dc] = sa2[not_dc]\n",
    "    proposed_s2[dc]     = s21[dc]\n",
    "    proposed_s2[not_dc] = s22[not_dc]\n",
    "\n",
    "    proposed_t = (proposed_sa, proposed_s2)\n",
    "    res.append((proposed_t, tuple(dc)))\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "def relabel_generic(args):\n",
    "    return transitions_and_masks_to_proposals(*args)\n",
    "\n",
    "\n",
    "def enlarge_dataset_generic(states, actions, next_states, num_pairs, relabel_samples_per_pair,\n",
    "                    batch_get_mask=None, add_bad_dcs=False):\n",
    "    \"\"\"\n",
    "    This does random coda on generic data, using the following types:\n",
    "    Inputs:\n",
    "    states, next_states: [batch, n_components, state_feats]             # NOTE: assumes 1d state feats\n",
    "    actions: [batch, action_feats] or [batch, n_components, action_feats]\n",
    "    custom_get_mask: (batch_states, batched_actions) -> [batch_dim, state_feats + action_feats, state_feats + action_feats]\n",
    "    Returns:\n",
    "    (new_states, new_actions, new_next_states) with same shapes as inputs (except batch_dim)\n",
    "    \"\"\"\n",
    "\n",
    "    map_fn  = map\n",
    "\n",
    "    data_len, n_state_components, n_state_feats = states.shape\n",
    "    squeeze_on_return = False\n",
    "    if len(actions.shape) == 2:\n",
    "        n_action_components = 1\n",
    "        squeeze_on_return = True\n",
    "        actions = actions[:, None]\n",
    "    else:\n",
    "        n_action_components = actions.shape[1]\n",
    "\n",
    "    masks = batch_get_mask(states, actions)\n",
    "\n",
    "    assert masks.shape[1] == masks.shape[2] == n_state_components + n_action_components\n",
    "\n",
    "    bad_dcs = set([(), tuple(list(range(n_state_components + n_action_components)))])\n",
    "\n",
    "    Is = np.random.randint(data_len, size=(num_pairs,))\n",
    "    Js = np.random.randint(data_len, size=(num_pairs,))\n",
    "\n",
    "    t1s = list(zip(batch_block_diag(states[Is], actions[Is]), batch_block_diag(next_states[Is], actions[Is])))\n",
    "    t2s = list(zip(batch_block_diag(states[Js], actions[Js]), batch_block_diag(next_states[Js], actions[Js])))\n",
    "\n",
    "    m1s = masks[Is]\n",
    "    m2s = masks[Js]\n",
    "\n",
    "    args = [(t1, t2, m1, m2, relabel_samples_per_pair) for t1, t2, m1, m2 in zip(t1s, t2s, m1s, m2s)]\n",
    "\n",
    "    proposals_and_dcs = map_fn(relabel_generic, args)\n",
    "    proposals_and_dcs = sum(proposals_and_dcs, []) # [((sa1, sa2), dc), ... ]\n",
    "\n",
    "    new_s1s = []\n",
    "    new_a1s = []\n",
    "    new_s2s = []\n",
    "    dcs     = []\n",
    "\n",
    "    for (sa1, sa2), dc in proposals_and_dcs:\n",
    "        if (not add_bad_dcs) and (dc in bad_dcs):\n",
    "            continue\n",
    "        new_s1s.append(sa1[:n_state_components, :n_state_feats])\n",
    "        new_a1s.append(sa1[n_state_components:, n_state_feats:])\n",
    "        new_s2s.append(sa2[:n_state_components, :n_state_feats])\n",
    "        dcs.append(dc)\n",
    "\n",
    "\n",
    "    new_s1s = np.array(new_s1s)\n",
    "    new_a1s = np.array(new_a1s)\n",
    "    new_s2s = np.array(new_s2s)\n",
    "\n",
    "    if not len(new_s1s):\n",
    "        return (new_s1s, new_a1s, new_s2s)\n",
    "\n",
    "    masks = batch_get_mask(new_s1s, new_a1s)\n",
    "    pdcs  = map_fn(get_dcs_from_mask, masks)\n",
    "\n",
    "    # Now verify that proposals are valid\n",
    "    valid_idxs = []\n",
    "    for i, (pdc, dc) in enumerate(zip(pdcs, dcs)):\n",
    "        if dc in pdc:\n",
    "            valid_idxs.append(i)\n",
    "\n",
    "    new_s1s = new_s1s[valid_idxs]\n",
    "    new_a1s = new_a1s[valid_idxs]\n",
    "    new_s2s = new_s2s[valid_idxs]\n",
    "\n",
    "    if squeeze_on_return:\n",
    "        new_a1s = new_a1s.squeeze(1)\n",
    "\n",
    "\n",
    "    return (new_s1s, new_a1s, new_s2s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coda_images(t1,t2,encoder,dynamics):\n",
    "    with torch.no_grad():\n",
    "        image1, action1 = t1\n",
    "        mask1,_ = dynamics.get_causal_mask(image1/255., action1,encoder=encoder,head_fusion=\"max\",discard_ratio=0.98)\n",
    "\n",
    "        image2, action2 = t2\n",
    "        mask2,_ = dynamics.get_causal_mask(image2/255., action2,encoder=encoder,head_fusion=\"max\",discard_ratio=0.98)\n",
    "    \n",
    "    mask1 = mask1.cpu().numpy().transpose(0,2,1)[0]\n",
    "    mask2 = mask2.cpu().numpy().transpose(0,2,1)[0]\n",
    "    \n",
    "    t1_sa = np.arange(mask1.shape[0])\n",
    "    t1_s2 = np.arange(mask1.shape[0] - action1.shape[1])\n",
    "    \n",
    "    t2_sa = np.arange(mask2.shape[0])\n",
    "    t2_s2 = np.arange(mask2.shape[0] - action2.shape[1])\n",
    "    \n",
    "    t1 = (t1_sa,t1_s2)\n",
    "    t2 = (t2_sa,t2_s2)\n",
    "    res = transitions_and_masks_to_proposals(t1,\n",
    "                                       t2,\n",
    "                                       mask1,\n",
    "                                       mask2,\n",
    "                                       max_samples=10,\n",
    "                                       max_ccs=20)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1_idx = 95\n",
    "t2_idx = 127\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_patches(dataset[t1_idx][0][0], patch_size=(enc_dec.patch_size,enc_dec.patch_size), num_patches_sqrt=image[0].shape[2]//enc_dec.patch_size);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_patches(dataset[t2_idx][0][0], patch_size=(enc_dec.patch_size,enc_dec.patch_size), num_patches_sqrt=image[0].shape[2]//enc_dec.patch_size);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def swap_transition_components(patches1,patches2, action1,action2, next_patches1, next_patches2, cc1_to_swap,cc2_to_swap):\n",
    "    \n",
    "    swapped_patches = []\n",
    "    swapped_actions = []\n",
    "    swapped_next_patches = []\n",
    "    for cc1,cc2 in zip(cc1_to_swap,cc2_to_swap):\n",
    "        \n",
    "        # swap actions\n",
    "        new_action1 = action1.clone()\n",
    "        new_action2 = action2.clone()\n",
    "        action1_idx = [act - patches1.shape[0] for act in cc1[\"actions\"]]\n",
    "        action2_idx = [act - patches1.shape[0] for act in cc2[\"actions\"]]\n",
    "        \n",
    "        new_action1[action1_idx] = action2[action2_idx]\n",
    "        new_action2[action2_idx] = action1[action1_idx]\n",
    "        \n",
    "        swapped_actions.append(new_action1)\n",
    "        swapped_actions.append(new_action2)\n",
    "        \n",
    "        cc1_wo_act = cc1[\"patches\"]\n",
    "        cc2_wo_act = cc2[\"patches\"]\n",
    "        \n",
    "        # swap current image patches\n",
    "        new_patches1 = patches1.clone()\n",
    "        new_patches2 = patches2.clone()\n",
    "        \n",
    "        new_patches1[cc1_wo_act], new_patches1[cc2_wo_act] = patches2[cc1_wo_act], patches2[cc2_wo_act]\n",
    "        swapped_patches.append(new_patches1)\n",
    "        new_patches2[cc1_wo_act], new_patches2[cc2_wo_act] = patches1[cc1_wo_act], patches1[cc2_wo_act]\n",
    "        swapped_patches.append(new_patches2)\n",
    "\n",
    "        # swap next image patches\n",
    "        new_next_patches1 = next_patches1.clone()\n",
    "        new_next_patches2 = next_patches2.clone()\n",
    "        new_next_patches1[cc1_wo_act], new_next_patches1[cc2_wo_act] = next_patches2[cc1_wo_act], next_patches2[cc2_wo_act]\n",
    "        swapped_next_patches.append(new_next_patches1)\n",
    "        new_next_patches2[cc1_wo_act], new_next_patches2[cc2_wo_act] = next_patches2[cc1_wo_act], next_patches2[cc2_wo_act]\n",
    "        swapped_next_patches.append(new_patches2)\n",
    "\n",
    "    return swapped_patches, swapped_actions, swapped_next_patches\n",
    "        \n",
    "\n",
    "def get_ccs_to_swap(m1,m2,num_actions):\n",
    "    cc1 = get_cc_dicts_from_mask(m1,num_patches=m1.shape[0]-num_actions,num_actions=num_actions)    \n",
    "    cc2 = get_cc_dicts_from_mask(m2,num_patches=m1.shape[0]-num_actions,num_actions=num_actions)   \n",
    "    \n",
    "    num_patches = m1.shape[0] - num_actions\n",
    "    \n",
    "    action_ccs1 = [cc for cc in cc1 if len(cc[\"actions\"]) > 0]\n",
    "    action_ccs2 = [cc for cc in cc2 if len(cc[\"actions\"]) > 0]\n",
    "    \n",
    "    print(\"action_ccs1\",action_ccs1)\n",
    "    print(\"action_ccs2\",action_ccs2)\n",
    "    ccs1_to_swap = []\n",
    "    ccs2_to_swap = []\n",
    "    for act_cc1 in action_ccs1:\n",
    "        \n",
    "        can_swap_cc = True\n",
    "        print(act_cc1)\n",
    "        if len(act_cc1[\"actions\"]) > 1:\n",
    "            can_swap_cc = False\n",
    "        #if (act_cc1 > (num_patches-1)).sum() != 1:\n",
    "        #    print(f\"{(act_cc1> (num_patches-1)).sum()} actions in big cc\" )\n",
    "        #    can_swap_cc = False\n",
    "            \n",
    "        act_cc1_action = act_cc1[\"actions\"][0]\n",
    "        cc2_same_act = [c for c in cc2 if act_cc1_action in c[\"actions\"]][0]\n",
    "        \n",
    "        if len(cc2_same_act[\"actions\"]) > 1:\n",
    "            can_swap_cc = False\n",
    "        #if (cc2_same_act > (num_patches-1)).sum() != 1:\n",
    "        #    print(\"Action of the big cc1 is in connected component of more than one action in cc2 \")\n",
    "        #    can_swap_cc = False\n",
    "\n",
    "        cc1_wo_action_cc = remove_component_with_action(act_cc1_action,cc1)\n",
    "        for c in cc2_same_act[\"patches\"]:\n",
    "            if not indep_comp_in_other(c,cc1_wo_action_cc):      \n",
    "                print(\"Component of cc2 with same action as big cc1 is not independent in cc1\")\n",
    "                can_swap_cc = False\n",
    "\n",
    "        cc2_wo_action = remove_component_with_action(act_cc1_action,cc2)\n",
    "        for c in act_cc1[\"patches\"]:\n",
    "            if not indep_comp_in_other(c,cc2_wo_action):      \n",
    "                print(\"not indep\")\n",
    "                can_swap_cc = False \n",
    "                \n",
    "        if not can_swap_cc:\n",
    "            continue\n",
    "        print(\"We can swap the patches\")\n",
    "        ccs1_to_swap.append(act_cc1)\n",
    "        ccs2_to_swap.append(cc2_same_act)\n",
    "\n",
    "    return ccs1_to_swap, ccs2_to_swap\n",
    "\n",
    "\n",
    "def get_transition_data(dataset, t_idx,use_gt_mask,encoder=None,dynamics=None,patch_size=16,num_actions=4):\n",
    "    image, action, next_image = dataset[t_idx][0], dataset[t_idx][1],dataset[t_idx][2]\n",
    "    image = image[0]\n",
    "    next_image = next_image[0]\n",
    "    action = action[0]\n",
    "    if use_gt_mask:\n",
    "        images = torch.stack([image,next_image])\n",
    "        mask = make_gt_causal_mask(images.unsqueeze(0),action.unsqueeze(0),\n",
    "                                   patch_size=patch_size,num_sprites=num_actions)\n",
    "    else:\n",
    "        mask, _ = dynamics.get_causal_mask(image.unsqueeze(0)/255., action.unsqueeze(0),encoder=encoder,head_fusion=\"max\",discard_ratio=0.98)\n",
    "        mask = mask > 0.2\n",
    "    mask = mask.cpu().numpy().transpose(0,2,1)[0]\n",
    "    \n",
    "    return image, action, next_image, mask    \n",
    "    \n",
    "    \n",
    "def do_coda_on_transition(dataset, t1_idx, t2_idx, patch_size,num_actions,use_gt_mask,encoder=None,dynamics=None):\n",
    "    \n",
    "    image1, action1, next_image1, mask1 = get_transition_data(dataset, t1_idx,use_gt_mask=use_gt_mask,encoder=encoder,dynamics=dynamics,patch_size=patch_size,num_actions=num_actions)    \n",
    "    image2, action2, next_image2, mask2 = get_transition_data(dataset, t2_idx,use_gt_mask=use_gt_mask,encoder=encoder,dynamics=dynamics,patch_size=patch_size,num_actions=num_actions)\n",
    "        \n",
    "    patches1 = image_to_patches(image1, patch_size=(patch_size,patch_size),num_patches_sqrt=image1.shape[2]//patch_size)\n",
    "    patches2 = image_to_patches(image2, patch_size=(patch_size,patch_size),num_patches_sqrt=image2.shape[2]//patch_size)\n",
    "\n",
    "    next_patches1 = image_to_patches(next_image1, patch_size=(patch_size,patch_size),num_patches_sqrt=image1.shape[2]//patch_size)\n",
    "    next_patches2 = image_to_patches(next_image2, patch_size=(patch_size,patch_size),num_patches_sqrt=image2.shape[2]//patch_size)\n",
    "\n",
    "    comp_to_swap_ccs1, comp_to_swap_ccs2 = get_ccs_to_swap(mask1,mask2,num_actions)\n",
    "    \n",
    "    coda_transitions = swap_transition_components(patches1,patches2, action1,action2, next_patches1, next_patches2, \n",
    "                                        comp_to_swap_ccs1,comp_to_swap_ccs2)\n",
    "    \n",
    "    \n",
    "    return coda_transitions\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_swapped_patches, swapped_actions, swapped_next_patches = do_coda_on_transition(dataset,t1_idx,t2_idx,16,4,use_gt_mask=True,encoder=None,dynamics=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GT swapped patches\",len(gt_swapped_patches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coda_images = patches_to_image(torch.stack(gt_swapped_patches),patch_size=16,image_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[t1_idx][0][0].permute(1,2,0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[t2_idx][0][0].permute(1,2,0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(coda_images[1].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swapped_patches, swapped_actions, swapped_next_patches = do_coda_on_transition(dataset,t1_idx,t2_idx,16,4,use_gt_mask=False,encoder=enc_dec,dynamics=dynamics_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(swapped_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coda_images = patches_to_image(torch.stack(swapped_patches),patch_size=16,image_size=128)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coda_next_images = patches_to_image(torch.stack(swapped_next_patches),patch_size=16,image_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[t1_idx][0][0].permute(1,2,0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(dataset[t2_idx][0][0].permute(1,2,0).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(coda_images[1].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(coda_next_images[0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_samples = 100\n",
    "\n",
    "print(\"created disconnected components\")\n",
    "# get shared connected components in random order\n",
    "shared_dc = list(dc1.intersection(dc2))\n",
    "random.shuffle(shared_dc)\n",
    "\n",
    "# subsample shared_dc down to max_samples\n",
    "if len(shared_dc) > max_samples:\n",
    "    shared_dc = shared_dc[:max_samples]\n",
    "\n",
    "#print(\"shared_dc\", shared_dc)\n",
    "all_idxs = set(range(len(sa1)))\n",
    "\n",
    "res = []\n",
    "for dc in shared_dc:\n",
    "    not_dc = list(all_idxs - set(dc))\n",
    "    dc = list(dc) # (0, 2)\n",
    "\n",
    "    print(len(dc))\n",
    "    proposed_sa = np.zeros_like(sa1)\n",
    "    proposed_s2 = np.zeros_like(sa1)\n",
    "\n",
    "    proposed_sa[dc]     = sa1[dc]\n",
    "    proposed_sa[not_dc] = sa2[not_dc]\n",
    "    proposed_s2[dc]     = s21[dc]\n",
    "    proposed_s2[not_dc] = s22[not_dc]\n",
    "\n",
    "    print(proposed_sa)\n",
    "    proposed_t = (proposed_sa, proposed_s2)\n",
    "    res.append((proposed_t, tuple(dc)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# get_dcs_from_mask should return a set of tuples of indices, inc. the empty tuple\n",
    "# where the subgraph represented by each tuple is disconnected from the result of \n",
    "# the graph. Note that mask should be square, so columns corresp. to action idxs are \n",
    "# dummy columns.\n",
    "#\n",
    "# E.g., if mask is [[1,0,0,0],[0,1,0,0],[0,0,1,1],[0,0,1,1]],\n",
    "# this function should return:\n",
    "#   set([ (,), (0,), (1,), (0,1), (2, 3), (0, 2, 3), (1, 2, 3), (0, 1, 2, 3)  ])\n",
    "\n",
    "print(\"creating disconnected components\")\n",
    "dc1 = get_dcs_from_mask(m1, max_ccs)\n",
    "dc2 = get_dcs_from_mask(m2, max_ccs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keep_n_patches(transition, mask,num_patches_keep, num_actions=4):\n",
    "    t_s1a = transition[0]\n",
    "    t_s2  = transition[1]\n",
    "    \n",
    "    t_s1a_n = np.hstack((t_s1a[:num_patches_keep],t_s1a[-num_actions:]))\n",
    "    t_s2_n = np.hstack((t_s2[:num_patches_keep],t_s2[-num_actions:]))\n",
    "    mask_n_top =  np.hstack((mask[:num_patches_keep,:num_patches_keep],mask[:num_patches_keep, -num_actions:] ))\n",
    "    mask_n_bot = np.hstack((mask[-num_actions:,:num_patches_keep],mask[-num_actions:, -num_actions:] ))\n",
    "    mask_n = np.vstack((mask_n_top,mask_n_bot))\n",
    "    return (t_s1a_n, t_s2_n), mask_n\n",
    "\n",
    "\n",
    "def keep_trans_slice(transition, mask,slice_keep, num_actions=4):\n",
    "    ## here the states and actions are just the indices\n",
    "    assert slice_keep[-1] <= (mask.shape[0] - num_actions)\n",
    "    \n",
    "    t_s1a = transition[0]\n",
    "    t_s2  = transition[1]\n",
    "\n",
    "    t_s1a_n = np.hstack((t_s1a[slice_keep[0]:slice_keep[1]],t_s1a[-num_actions:]))\n",
    "    t_s2_n = np.hstack((t_s2[slice_keep[0]:slice_keep[1]],t_s2[-num_actions:]))\n",
    "    mask_n_top =  np.hstack((mask[slice_keep[0]:slice_keep[1],slice_keep[0]:slice_keep[1]],mask[slice_keep[0]:slice_keep[1], -num_actions:] ))\n",
    "    mask_n_bot = np.hstack((mask[-num_actions:,slice_keep[0]:slice_keep[1]],mask[-num_actions:, -num_actions:] ))\n",
    "    mask_n = np.vstack((mask_n_top,mask_n_bot))\n",
    "    return (t_s1a_n, t_s2_n), mask_n\n",
    "    \n",
    "    \n",
    "def make_trans_coda(dataset, t_idx1, t_idx2,encoder,dynamics):\n",
    "    image1, action1 = dataset[t_idx1][0], dataset[t_idx1][1]\n",
    "    image2, action2 = dataset[t_idx2][0], dataset[t_idx2][1]\n",
    "    with torch.no_grad():\n",
    "        image1, action1 = t1\n",
    "        mask1,_ = dynamics.get_causal_mask(image1/255., action1,encoder=encoder,head_fusion=\"max\",discard_ratio=0.98)\n",
    "\n",
    "        image2, action2 = t2\n",
    "        mask2,_ = dynamics.get_causal_mask(image2/255., action2,encoder=encoder,head_fusion=\"max\",discard_ratio=0.98)\n",
    "\n",
    "    m1 = mask1.cpu().numpy().transpose(0,2,1)[0]\n",
    "    m2 = mask2.cpu().numpy().transpose(0,2,1)[0]\n",
    "\n",
    "    t1_sa = np.arange(mask1.shape[0])\n",
    "    t1_s2 = np.arange(mask1.shape[0])\n",
    "\n",
    "    t2_sa = np.arange(mask2.shape[0])\n",
    "    t2_s2 = np.arange(mask2.shape[0])\n",
    "\n",
    "    t1 = (t1_sa,t1_s2)\n",
    "    t2 = (t2_sa,t2_s2)\n",
    "    return (t1,m1), (t2,m2)\n",
    "\n",
    "\n",
    "def swap_transitions(patches_image1_s1,action1,patches_image1_s2,patches_image2_s1,action2,patches_image2_s2,t2_to_t1):\n",
    "    patches_image1_s1 = patches_image1_s1.clone()\n",
    "    action1 = action1.clone()\n",
    "    patches_image1_s2 = patches_image1_s2.clone()\n",
    "    patches_image1_s1[t2_to_t1] = patches_image2_s1[t2_to_t1]\n",
    "    action1[t2_to_t1] = action2[t2_to_t1]\n",
    "    patches_image1_s2[t2_to_t1] = patches_image2_s2[t2_to_t1]\n",
    "    \n",
    "    return patches_image1_s1,action1, patches_image1_s2\n",
    "\n",
    "def do_coda(dataset,\n",
    "            t_idx1,\n",
    "            t_idx2,\n",
    "            encoder,\n",
    "            dynamics,\n",
    "            num_patches_keep=16,\n",
    "            ground_truth_mask=False,\n",
    "            max_samples=100):\n",
    "    \n",
    "    \n",
    "    image1_s1, action1 = dataset[t_idx1][0], dataset[t_idx1][1]\n",
    "    image1_s2 = dataset[t_idx1+1][0] # need to check if sequence ended or not\n",
    "    image2_s1, action2 = dataset[t_idx2][0], dataset[t_idx2][1]\n",
    "    image2_s2 = dataset[t_idx2+1][0]\n",
    "    \n",
    "    \n",
    "    image1_s1_patches = image_to_patches(image1_s1,patch_size=16,num_patches_sqrt=8)\n",
    "    image2_s1_patches = image_to_patches(image2_s1,patch_size=16,num_patches_sqrt=8)\n",
    "    \n",
    "    image1_s2_patches = image_to_patches(image1_s2,patch_size=16,num_patches_sqrt=8)\n",
    "    image2_s2_patches = image_to_patches(image2_s2,patch_size=16,num_patches_sqrt=8)\n",
    "    \n",
    "    if ground_truth_mask:\n",
    "        t1m1, t2m2 = make_gt_trans_coda(dataset, t_idx1, t_idx2)\n",
    "    else:\n",
    "        t1m1, t2m2 = make_trans_coda(dataset, t_idx1, t_idx2,encoder,dynamics)\n",
    "    \n",
    "    t1 = t1m1[0]\n",
    "    m1 = t1m1[1]\n",
    "    t2 = t2m2[0]\n",
    "    m2 = t2m2[1]\n",
    "    num_iter = (m1.shape[0] - dynamics.action_embedding.num_actions)//num_patches_keep\n",
    "    \n",
    "    coda_images = []\n",
    "    coda_actions = []\n",
    "    for i in range(num_iter):\n",
    "        t1_n, mask1_n = keep_trans_slice(t1, m1,num_patches_keep)\n",
    "        t2_n, mask2_n = keep_trans_slice(t2, m2,num_patches_keep) \n",
    "        dcs = get_dcs(mask1_n,mask2_n,max_ccs=num_patches_keep,max_samples=max_samples)    \n",
    "        coda_images_part = []\n",
    "        coda_actions_part = []\n",
    "        for (dc,not_dc) in dcs:\n",
    "            new_s1, new_action1, new_s2 = swap_transitions(image1_s1_patches,action1,image1_s2_patches,image2_s1_patches,action2,image2_s2_patches,dc,not_dc)\n",
    "            coda_images_part.append(torch.stack([new_s1,new_s2]))\n",
    "            coda_actions_part.append(torch.stack([new_action1]))\n",
    "            \n",
    "        coda_images_part = torch.stack(coda_images_part)\n",
    "        \n",
    "        max_coda_diff_idx = (image1_s1_patches - coda_images_part[:,0]).abs().sum(axis=(1,2,3)).argmax()\n",
    "        \n",
    "        coda_images.append(coda_images_part[max_coda_diff_idx])\n",
    "        coda_actions.append(coda_actions_part[max_coda_diff_idx])\n",
    "        \n",
    "    return coda_images[:,0], coda_actions, coda_images[:,1]\n",
    "            \n",
    "            \n",
    "def get_dcs(m1,m2,max_ccs=16,max_samples=100):\n",
    "    dc1 = get_dcs_from_mask(m1, max_ccs)\n",
    "    dc2 = get_dcs_from_mask(m2, max_ccs)\n",
    "    shared_dc = list(dc1.intersection(dc2))\n",
    "    random.shuffle(shared_dc)\n",
    "\n",
    "    # subsample shared_dc down to max_samples\n",
    "    if len(shared_dc) > max_samples:\n",
    "        shared_dc = shared_dc[:max_samples]\n",
    "    all_idxs = set(range(len(m1.shape[0])))\n",
    "\n",
    "    res = []\n",
    "    for dc in shared_dc:\n",
    "        not_dc = list(all_idxs - set(dc))\n",
    "        dc = list(dc) # (0, 2)\n",
    "        res.append((tuple(dc), tuple(not_dc)))\n",
    "        \n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coda_act = torch.load(\"/cluster/home/gboeshertz/patch_rl/outputs/train_agent/4/2022.12.07/141030/coda_act.pt\")\n",
    "coda_obs = torch.load(\"/cluster/home/gboeshertz/patch_rl/outputs/train_agent/4/2022.12.07/141030/coda_obs.pt\")\n",
    "coda_next_obs = torch.load(\"/cluster/home/gboeshertz/patch_rl/outputs/train_agent/4/2022.12.07/141030/coda_next_obs.pt\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = torch.load(\"/cluster/home/gboeshertz/patch_rl/outputs/train_agent/4/2022.12.07/141030/act.pt\")\n",
    "obs = torch.load(\"/cluster/home/gboeshertz/patch_rl/outputs/train_agent/4/2022.12.07/141030/obs.pt\")\n",
    "next_obs = torch.load(\"/cluster/home/gboeshertz/patch_rl/outputs/train_agent/4/2022.12.07/141030/next_obs.pt\")\n",
    "rewards = torch.load(\"/cluster/home/gboeshertz/patch_rl/outputs/train_agent/4/2022.12.07/141030/rewards.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(obs[90,0].numpy().transpose(1,2,0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(coda_obs[10,0].transpose(1,2,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mask_utils import get_cc_dicts_from_mask,get_cc_from_mask,get_ccs_to_swap,swap_transition_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gym\n",
    "import hydra\n",
    "from moog import environment\n",
    "from moog.env_wrappers import gym_wrapper\n",
    "from moog_demos.example_configs import bouncing_sprites\n",
    "from stable_baselines3.common.utils import set_random_seed\n",
    "from stable_baselines3.common.logger import configure\n",
    "from src.mask_utils import make_gt_causal_mask, get_cc_dicts_from_mask, gt_reward_function\n",
    "from omegaconf import OmegaConf\n",
    "import os \n",
    "import wandb\n",
    "from wandb.integration.sb3 import WandbCallback\n",
    "from stable_baselines3.common.logger import configure\n",
    "from src.networks.cnns import Conv2dModel\n",
    "import d3rlpy\n",
    "import logging\n",
    "from tensorboard.util import tb_logging\n",
    "import wandb\n",
    "from src.coda_dataset import CodaDataset\n",
    "from src.datasets import ImageTransitionDataset\n",
    "from src.d3rl_feature_extractor import PatchCNNFactory, PatchVAEFactory\n",
    "from hydra.utils import get_original_cwd, to_absolute_path\n",
    "import numpy as np\n",
    "from d3rlpy.metrics.scorer import initial_state_value_estimation_scorer\n",
    "\n",
    "\n",
    "class _IgnoreTensorboardPathNotFound(logging.Filter):\n",
    "    def filter(self, record):\n",
    "        assert record.name == \"tensorboard\"\n",
    "        if \"No path found after\" in record.msg:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "\n",
    "class ImageReshaper(gym.ObservationWrapper):\n",
    "    def __init__(self, env):\n",
    "        super(ImageReshaper, self).__init__(env)\n",
    "        self.observation_space = gym.spaces.Box(\n",
    "            low=0, high=255, shape=(3, 128, 128), dtype=np.uint8)\n",
    "\n",
    "    def observation(self, observation):\n",
    "        return observation.transpose(2, 0, 1)\n",
    "\n",
    "def make_mask_function(image,action,next_image,  encoder=None,dynamics=None, make_gt_mask=False,patch_size=16, num_sprites=4):\n",
    "    \n",
    "    if make_gt_mask:\n",
    "        mask = make_gt_causal_mask(image, action, next_image, num_sprites=num_sprites,patch_size=patch_size[0])\n",
    "    else:\n",
    "        assert encoder is not None\n",
    "        mask = dynamics.get_causal_mask(image, action,encoder=encoder, discard_ratio=0.95,head_fusion=dynamics.head_fusion)\n",
    "    return mask\n",
    "\n",
    "def make_reward_function(image, action, next_image, encoder=None,dynamics=None,make_gt_reward=False):    \n",
    "    \n",
    "    if make_gt_reward:\n",
    "        rewards = gt_reward_function(image,next_image)\n",
    "    else:\n",
    "        assert encoder is not None\n",
    "        rewards = dynamics.get_rewards(image, action,encoder=encoder)\n",
    "    return rewards\n",
    "\n",
    "\n",
    "def setup_dataset(config,env):\n",
    "\n",
    "    coda_data_path = f\"..{config.coda_dataset_path}\"\n",
    "    \n",
    "    if config.load_dataset:\n",
    "        print(f\"Loading dataset from {coda_data_path}\")\n",
    "        coda_dataset = ImageTransitionDataset(coda_data_path)\n",
    "    else:\n",
    "        encoder_decoder = dynamics_model = None\n",
    "\n",
    "        mask_function = lambda image, next_image, action: make_mask_function(image, next_image,action, encoder=encoder_decoder,dynamics=dynamics_model, make_gt_mask=config.dataset.use_gt_mask,patch_size=config.dataset.patch_size, num_sprites=4)\n",
    "        reward_function = lambda image, action, next_image: make_reward_function(image, action,next_image, encoder=encoder_decoder,dynamics=dynamics_model,make_gt_reward=config.dataset.use_gt_reward)\n",
    "\n",
    "        data_path = f\"..{config.dataset_path}\"\n",
    "        dataset = ImageTransitionDataset(data_path)\n",
    "        print(\"Creating CoDA data\")\n",
    "        coda_dataset = CodaDataset(dataset,max_coda_transitions=config.dataset.max_coda_transitions ,mask_function=mask_function,\n",
    "                                   reward_function=reward_function, patch_size=config.dataset.patch_size,\n",
    "                                   num_actions=env.action_space._shape[0],num_patches=config.dataset.num_patches)\n",
    "        if config.dataset.save_coda_dataset:\n",
    "            coda_dataset.save(coda_data_path)\n",
    "            \n",
    "    return coda_dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"configs/train_batch_agent.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using bouncing ball environment with 4 sprites\n",
      "<PIL.Image.Image image mode=RGB size=128x128 at 0x2AB83A8827C0>\n"
     ]
    }
   ],
   "source": [
    "eval_env_config = bouncing_sprites.get_config(num_sprites=4,is_demo=False,\n",
    "                                                        timeout_steps=100, \n",
    "                                                        contact_reward=True,\n",
    "                                                        one_sprite_mover=False,\n",
    "                                                        all_sprite_mover=True,\n",
    "                                                        discrete_all_sprite_mover=False,\n",
    "                                                        random_init_places=True,\n",
    "                                                        visual_obs = True,\n",
    "                                                        instant_move = True,\n",
    "                                                        action_scale=0.05,\n",
    "                                                        seed=0+10,\n",
    "                                                        disappear_after_contact=True,\n",
    "                                                        dont_show_targets=True)\n",
    "\n",
    "eval_env = environment.Environment(**eval_env_config)\n",
    "eval_env = ImageReshaper(gym_wrapper.GymWrapper(eval_env))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec BoundedArray(shape=(8,), dtype=dtype('float32'), name=None, minimum=-1.0, maximum=1.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/gboeshertz/miniconda3/envs/urlb/lib/python3.8/site-packages/gym/spaces/box.py:73: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Box([-1. -1. -1. -1. -1. -1. -1. -1.], [1. 1. 1. 1. 1. 1. 1. 1.], (8,), float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_env.action_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations shape torch.Size([5000, 3, 128, 128])\n",
      "Creating CoDA data\n",
      "Dataset obs max tensor(255.)\n",
      "Dataset obs min tensor(0.)\n",
      "Dataset obs mean tensor(1.6589)\n",
      "Dataset obs std tensor(20.5003)\n",
      "Masks shape: torch.Size([5000, 68, 68])\n",
      "Coda observations shape:  torch.Size([8, 3, 128, 128])\n",
      "Coda rewards shape:  torch.Size([8])\n",
      "Time to do coda 0.026158809661865234\n",
      "torch.uint8\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    }
   ],
   "source": [
    "encoder_decoder = dynamics_model = None\n",
    "\n",
    "mask_function = lambda image, next_image, action: make_mask_function(image, next_image,action, encoder=encoder_decoder,dynamics=dynamics_model, make_gt_mask=config.dataset.use_gt_mask,patch_size=config.dataset.patch_size, num_sprites=4)\n",
    "reward_function = lambda image, action, next_image: make_reward_function(image, action,next_image, encoder=encoder_decoder,dynamics=dynamics_model,make_gt_reward=config.dataset.use_gt_reward)\n",
    "\n",
    "data_path = f\"..{config.dataset_path}\"\n",
    "dataset = ImageTransitionDataset(data_path)\n",
    "print(\"Creating CoDA data\")\n",
    "coda_dataset = CodaDataset(dataset,max_coda_transitions=config.dataset.max_coda_transitions ,mask_function=mask_function,\n",
    "                            reward_function=reward_function, patch_size=config.dataset.patch_size,\n",
    "                            num_actions=8,num_patches=config.dataset.num_patches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def n_transition_list(dataset,n_transitions):\n",
    "    \n",
    "    transition_list = []\n",
    "    \n",
    "    n_obs = dataset.observations[:n_transitions].numpy()\n",
    "    n_actions = dataset.actions[:n_transitions].numpy()\n",
    "    n_next_obs = dataset.next_observations[:n_transitions].numpy()\n",
    "    n_rewards = dataset.rewards[:n_transitions].numpy()\n",
    "    n_dones = dataset.dones[:n_transitions].numpy()\n",
    "\n",
    "    if np.isnan(n_obs).any():\n",
    "        print(\"Nan in obs\")\n",
    "    if np.isnan(n_actions).any():\n",
    "        print(\"Nan in actions\")\n",
    "    if np.isnan(n_next_obs).any():\n",
    "        print(\"Nan in obs\")\n",
    "    if np.isnan(n_rewards).any():\n",
    "        print(\"Nan in rewards\")\n",
    "    if np.isnan(n_dones).any():\n",
    "        print(\"Nan in n_dones\")\n",
    "\n",
    "    print(f\"n_obs shape: {n_obs.shape}\")\n",
    "    print(\"Observations stats: \",np.min(n_obs),np.max(n_obs),np.mean(n_obs),np.std(n_obs))\n",
    "    print(\"Next observations stats: \",np.min(n_next_obs),np.max(n_next_obs),np.mean(n_next_obs),np.std(n_next_obs))\n",
    "    print(\"Rewards stats: \",np.min(n_rewards),np.max(n_rewards),np.mean(n_rewards),np.std(n_rewards))\n",
    "    print(\"Actions stats: \",np.min(n_actions),np.max(n_actions),np.mean(n_actions),np.std(n_actions))\n",
    "\n",
    "    terminals = n_dones * (n_rewards>0)\n",
    "    print(\"Terminal stats: \",np.min(terminals),np.max(terminals),np.mean(terminals),np.std(terminals))\n",
    "    for i in range(0,n_obs.shape[0]):\n",
    "        trans = d3rlpy.dataset.Transition(observation_shape=list(n_obs[i].shape),\n",
    "                                          action_size=n_actions[i].shape[0],\n",
    "                                          observation=n_obs[i].astype(np.uint8),\n",
    "                                          action=n_actions[i].astype(np.float32),\n",
    "                                          reward= float(n_rewards[i]),\n",
    "                                          next_observation=n_next_obs[i].astype(np.uint8),\n",
    "                                          terminal= float(terminals[i]))\n",
    "        transition_list.append(trans)\n",
    "    \n",
    "    print(f\"Transition list length: {len(transition_list)}\")\n",
    "    return transition_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coda_dataset.dones.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(coda_dataset.dones * (coda_dataset.rewards>0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = eval_env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_list = n_transition_list(dataset,5000)\n",
    "c_list = n_transition_list(coda_dataset,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.mask_utils import gt_count_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = OmegaConf.load(\"configs/train_batch_agent.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = setup_dataset(config,eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    print(\"Image \",i)\n",
    "    img_idx = np.random.choice(100,1)\n",
    "    img = dataset.observations[img_idx[0]]\n",
    "    print(\"Image shape\",img.shape)\n",
    "    print(\"GT count\",gt_count_function(img.unsqueeze(0),4))\n",
    "\n",
    "    plt.imshow(img.permute(1,2,0))\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "e = torch.ones(4,4).type(torch.uint8)\n",
    "e[0,0]= 255\n",
    "f = torch.ones(2,4).float()\n",
    "f[1,1] = 256\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = torch.cat((e,f),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[255.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.],\n",
       "        [  1.,   1.,   1.,   1.],\n",
       "        [  1., 256.,   1.,   1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "urlb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cfb27034fd4e2f98c77e8589e2cce571552edcefb0dada44243fe417e779478"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
