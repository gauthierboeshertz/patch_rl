_target_: src.dynamics_model.AttentionDynamicsModel
num_heads: 8
mlp_dim: 256
num_attention_layers: 1
dropout: 0.2
action_dim: 8
in_features: -1
num_patches: -1
group_actions: False
residual: True
use_attn_mask: False
discrete_actions: True
num_actions: -1
embed_dim: 1024
device: cpu
use_gt_mask: False
regularizer_weight: 0
head_disagreement_weight: 100
action_regularization_weight: 0
temperature: 0.2
end_residual: False
causal_mask_threshold: 0.3
discretize_actions: False
num_discrete_bins: 4
predict_rewards: False
num_rewards: ???
reward_loss_weight: 0.01
