{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.signal import savgol_filter\n",
    "sys.path.append('../')\n",
    "\n",
    "\n",
    "from six.moves import xrange\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import make_grid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorQuantizerEMA(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, commitment_cost, decay, epsilon=1e-5):\n",
    "        super(VectorQuantizerEMA, self).__init__()\n",
    "        \n",
    "        self._embedding_dim = embedding_dim\n",
    "        self._num_embeddings = num_embeddings\n",
    "        \n",
    "        self._embedding = nn.Embedding(self._num_embeddings, self._embedding_dim)\n",
    "        self._embedding.weight.data.normal_()\n",
    "        self._commitment_cost = commitment_cost\n",
    "        \n",
    "        self.register_buffer('_ema_cluster_size', torch.zeros(num_embeddings))\n",
    "        self._ema_w = nn.Parameter(torch.Tensor(num_embeddings, self._embedding_dim))\n",
    "        self._ema_w.data.normal_()\n",
    "        \n",
    "        self._decay = decay\n",
    "        self._epsilon = epsilon\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # convert inputs from BCHW -> BHWC\n",
    "        #inputs = inputs.permute(0, 2, 3, 1).contiguous()\n",
    "        input_shape = inputs.shape\n",
    "        \n",
    "        # Flatten input\n",
    "        flat_input = inputs.view(-1, self._embedding_dim)\n",
    "        \n",
    "        print('flat_input.shape', flat_input.shape)\n",
    "        # Calculate distances\n",
    "        distances = (torch.sum(flat_input**2, dim=1, keepdim=True) \n",
    "                    + torch.sum(self._embedding.weight**2, dim=1)\n",
    "                    - 2 * torch.matmul(flat_input, self._embedding.weight.t()))\n",
    "            \n",
    "        # Encoding\n",
    "        encoding_indices = torch.argmin(distances, dim=1).unsqueeze(1)\n",
    "        encodings = torch.zeros(encoding_indices.shape[0], self._num_embeddings, device=inputs.device)\n",
    "        encodings.scatter_(1, encoding_indices, 1)\n",
    "        \n",
    "        # Quantize and unflatten\n",
    "        quantized = torch.matmul(encodings, self._embedding.weight).view(input_shape)\n",
    "        \n",
    "        # Use EMA to update the embedding vectors\n",
    "        if self.training:\n",
    "            self._ema_cluster_size = self._ema_cluster_size * self._decay + \\\n",
    "                                     (1 - self._decay) * torch.sum(encodings, 0)\n",
    "            \n",
    "            # Laplace smoothing of the cluster size\n",
    "            n = torch.sum(self._ema_cluster_size.data)\n",
    "            self._ema_cluster_size = (\n",
    "                (self._ema_cluster_size + self._epsilon)\n",
    "                / (n + self._num_embeddings * self._epsilon) * n)\n",
    "            \n",
    "            dw = torch.matmul(encodings.t(), flat_input)\n",
    "            self._ema_w = nn.Parameter(self._ema_w * self._decay + (1 - self._decay) * dw)\n",
    "            \n",
    "            self._embedding.weight = nn.Parameter(self._ema_w / self._ema_cluster_size.unsqueeze(1))\n",
    "        \n",
    "        # Loss\n",
    "        e_latent_loss = F.mse_loss(quantized.detach(), inputs)\n",
    "        loss = self._commitment_cost * e_latent_loss\n",
    "        \n",
    "        # Straight Through Estimator\n",
    "        quantized = inputs + (quantized - inputs).detach()\n",
    "        avg_probs = torch.mean(encodings, dim=0)\n",
    "        perplexity = torch.exp(-torch.sum(avg_probs * torch.log(avg_probs + 1e-10)))\n",
    "        \n",
    "        # convert quantized from BHWC -> BCHW\n",
    "        return loss, quantized, perplexity, encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.networks.cnns import MLP\n",
    "class ActionVQVAE(nn.Module):\n",
    "    def __init__(self,embed_dim, num_embeddings, commitment_cost, decay, epsilon=1e-5):\n",
    "        super(ActionVQVAE, self).__init__()\n",
    "        self.encoder = MLP(2, embed_dim, [64, 64, 64])\n",
    "        self.vq = VectorQuantizerEMA(num_embeddings, embed_dim, commitment_cost, decay, epsilon)\n",
    "        self.decoder = MLP(embed_dim, 2, [64, 64, 64])\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        loss, quantized, perplexity, _ = self.vq(x)\n",
    "        x_recons = self.decoder(quantized)\n",
    "        return loss, x_recons, quantized, perplexity\n",
    "    \n",
    "    def compute_loss(self, x):\n",
    "        loss, x_recons, perplexity = self(x)\n",
    "        mse_loss = F.mse_loss(x_recons, x)\n",
    "        loss = loss + mse_loss\n",
    "        \n",
    "        loss_dict = {'loss': loss, 'mse_loss': mse_loss, 'vq_loss': loss, 'perplexity': perplexity}\n",
    "        return loss, loss_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from progress.bar import Bar\n",
    "import einops \n",
    "def train_epoch(model,optimizer, dataloader,device):\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    epoch_loss_dict = defaultdict(float)\n",
    "    for _, batch in enumerate(dataloader):\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        action = batch[1].to(device)\n",
    "        action = einops.rearrange(action, 'b t (n a) -> (b t n) a', a=2)\n",
    "        loss, loss_dict = model.compute_loss(action)\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 2.0)\n",
    "        optimizer.step()\n",
    "        for k in loss_dict:\n",
    "            epoch_loss_dict[k] += float(loss_dict[k])\n",
    "        total_loss += float(loss)\n",
    "        \n",
    "    for k in epoch_loss_dict:\n",
    "        epoch_loss_dict[k] /= len(dataloader)\n",
    "    return total_loss/len(dataloader), epoch_loss_dict\n",
    "\n",
    "def val_epoch(model,dataloader,device):\n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss_dict = defaultdict(float)\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for _, batch in enumerate(dataloader):\n",
    "            action = batch[1].to(device)\n",
    "            action = einops.rearrange(action, 'b t (n a) -> (b t n) a', a=2)\n",
    "            loss,  loss_dict = model.compute_loss(action)\n",
    "            for k in loss_dict:\n",
    "                epoch_loss_dict[k] += float(loss_dict[k])\n",
    "            total_loss += float(loss)\n",
    "            \n",
    "    for k in epoch_loss_dict:\n",
    "        epoch_loss_dict[k] /= len(dataloader)\n",
    "\n",
    "    return  total_loss/len(dataloader), epoch_loss_dict\n",
    "                \n",
    "\n",
    "\n",
    "def train(model, optimizer, train_dataloader, val_dataloader, num_epochs,device,scheduler):\n",
    "    info_bar = Bar('Training', max=num_epochs)\n",
    "    min_val_loss = 100000\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss, train_loss_dict = train_epoch(model,optimizer, train_dataloader,device)\n",
    "        val_loss, val_loss_dict = val_epoch(model,val_dataloader,device)   \n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        short_epoch_info = \"Epoch: {},  train Loss: {}, Val Loss: {}\".format(epoch,train_loss,val_loss )   \n",
    "        epoch_info = f\"Epoch: {epoch}, TRAIN: \"\n",
    "        for k in train_loss_dict:\n",
    "            epoch_info += f\"{k}: {train_loss_dict[k]:.5f}, \"\n",
    "        epoch_info += \"VAL: \"\n",
    "        for k in val_loss_dict:\n",
    "            epoch_info += f\"{k}: {val_loss_dict[k]:.5f}, \"\n",
    "        #epoch_info = f\"Epoch: {epoch},TRAIN : DYN Loss: {train_dyn_loss} VAE LOSS: {train_vae_loss}  INV LOSS: {train_inv_loss}||   VAL : DYN Loss: {val_dyn_loss} VAE LOSS: {val_vae_loss} INV LOSS: {val_inv_loss}\"\n",
    "        print(epoch_info)\n",
    "        #logger.info(epoch_info)\n",
    "        torch.save(model.state_dict(), f\"last_dynamics.pt\")\n",
    "        if min_val_loss > val_loss:\n",
    "            min_val_loss = val_loss\n",
    "            torch.save(model.state_dict(), f\"best_val_dynamics.pt\")\n",
    "\n",
    "        Bar.suffix = short_epoch_info\n",
    "        info_bar.next()\n",
    "    info_bar.finish()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 1, 128, 128, 3])\n",
      "Creating MLP with input size 2 and output size 2\n",
      "Creating MLP with layer sizes [64, 64, 64]\n",
      "Creating MLP with input size 2 and output size 2\n",
      "Creating MLP with layer sizes [64, 64, 64]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from src.datasets import SequenceImageTransitionDataset\n",
    "data_path = \"/cluster/home/gboeshertz/patch_rl/data/visual_150transitions_4_all_sprite_mover_True_4instantmoveno_targets.npz\"\n",
    "dataset = SequenceImageTransitionDataset(data_path=data_path,sequence_length=2,)\n",
    "\n",
    "train_dataset, val_dataset = torch.utils.data.random_split(dataset, [int(len(dataset)*0.8), len(dataset)-int(len(dataset)*0.8)])\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=128,shuffle=True,num_workers=1)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size=128,shuffle=False,num_workers=1)\n",
    "\n",
    "\n",
    "model = ActionVQVAE(2, 16, 0.25, 0.99)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, TRAIN: loss: 0.32786, mse_loss: 0.32777, vq_loss: 0.32786, perplexity: 1.00000, VAL: loss: 0.32050, mse_loss: 0.31877, vq_loss: 0.32050, perplexity: 1.00000, \n",
      "Epoch: 1, TRAIN: loss: 0.32485, mse_loss: 0.32318, vq_loss: 0.32485, perplexity: 1.00000, VAL: loss: 0.31642, mse_loss: 0.31604, vq_loss: 0.31642, perplexity: 1.00000, \n",
      "Epoch: 2, TRAIN: loss: 0.31939, mse_loss: 0.31901, vq_loss: 0.31939, perplexity: 1.00000, VAL: loss: 0.31427, mse_loss: 0.31402, vq_loss: 0.31427, perplexity: 1.00000, \n",
      "Epoch: 3, TRAIN: loss: 0.31590, mse_loss: 0.31565, vq_loss: 0.31590, perplexity: 1.00000, VAL: loss: 0.31282, mse_loss: 0.31253, vq_loss: 0.31282, perplexity: 1.00000, \n",
      "Epoch: 4, TRAIN: loss: 0.31310, mse_loss: 0.31278, vq_loss: 0.31310, perplexity: 1.00000, VAL: loss: 0.31192, mse_loss: 0.31155, vq_loss: 0.31192, perplexity: 1.00000, \n",
      "Epoch: 5, TRAIN: loss: 0.31085, mse_loss: 0.31045, vq_loss: 0.31085, perplexity: 1.00000, VAL: loss: 0.31150, mse_loss: 0.31104, vq_loss: 0.31150, perplexity: 1.00000, \n",
      "Epoch: 6, TRAIN: loss: 0.30908, mse_loss: 0.30861, vq_loss: 0.30908, perplexity: 1.00000, VAL: loss: 0.31156, mse_loss: 0.31100, vq_loss: 0.31156, perplexity: 1.00000, \n",
      "Epoch: 7, TRAIN: loss: 0.30784, mse_loss: 0.30728, vq_loss: 0.30784, perplexity: 1.00000, VAL: loss: 0.31200, mse_loss: 0.31134, vq_loss: 0.31200, perplexity: 1.00000, \n",
      "Epoch: 8, TRAIN: loss: 0.30707, mse_loss: 0.30643, vq_loss: 0.30707, perplexity: 1.00000, VAL: loss: 0.31279, mse_loss: 0.31201, vq_loss: 0.31279, perplexity: 1.00000, \n",
      "Epoch: 9, TRAIN: loss: 0.30670, mse_loss: 0.30596, vq_loss: 0.30670, perplexity: 1.00000, VAL: loss: 0.31379, mse_loss: 0.31287, vq_loss: 0.31379, perplexity: 1.00000, \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ActionVQVAE(\n",
       "  (encoder): MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (vq): VectorQuantizerEMA(\n",
       "    (_embedding): Embedding(16, 2)\n",
       "  )\n",
       "  (decoder): MLP(\n",
       "    (layers): Sequential(\n",
       "      (0): Linear(in_features=2, out_features=64, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=64, out_features=64, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=64, out_features=2, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flat_input.shape torch.Size([1, 2])\n"
     ]
    }
   ],
   "source": [
    "loss, recons,quant,_ = model(torch.randn(1,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-102.6851,   39.7359]]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(model, optimizer, train_dataloader, val_dataloader, 10,\"cpu\",scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionDiscretizer():\n",
    "    def __init__(self,num_actions, num_discrete_bins) -> None:\n",
    "        self.num_actions = num_actions\n",
    "        self.num_discrete_bins = num_discrete_bins\n",
    "        self.bins = torch.linspace(-1,1,self.num_discrete_bins)\n",
    "    \n",
    "    def discretize(self,action):\n",
    "        action = action.reshape(-1,self.num_actions)\n",
    "        action = torch.bucketize(action,self.bins)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_disc = ActionDiscretizer(2,16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10,  0]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act = torch.randn(1,2)\n",
    "print(act)\n",
    "print(act_disc.discretize(act))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('urlb')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0cfb27034fd4e2f98c77e8589e2cce571552edcefb0dada44243fe417e779478"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
